{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["URpHchL1INjJ","5L8fJz6ExiYo","Kgtj3EWDG2RR","sX9tgeJBh3mz"],"toc_visible":true,"authorship_tag":"ABX9TyOYwlvoMYZoA3g0ERrgmEs/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"URpHchL1INjJ"},"source":["# Prepairing"]},{"cell_type":"markdown","metadata":{"id":"E_N8vR5BGIVK"},"source":["## inSTAR PLATINum"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-cQvNN56If9","outputId":"611708fc-872e-49d0-ab61-3a36b134f320","executionInfo":{"status":"ok","timestamp":1705075625070,"user_tz":-60,"elapsed":48894,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["#hugging\n","!pip install -q transformers\n","!pip install -q datasets\n","\n","#keras\n","!pip install -q --upgrade keras-nlp\n","!pip install -q --upgrade keras"]},{"cell_type":"markdown","metadata":{"id":"BUKLkTT-Gn3Q"},"source":["## config"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"NbIf-I466KN2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705075637519,"user_tz":-60,"elapsed":12454,"user":{"displayName":"Husar","userId":"14076509305213519843"}},"outputId":"9eca0c32-a8a0-42c7-b0f7-662a1dca8617"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":2}],"source":["import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"torch\"\n","import keras_nlp\n","import keras\n","\n","import transformers\n","\n","import numpy as np\n","\n","import torch\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","DEVICE"]},{"cell_type":"markdown","metadata":{"id":"b2xkNhq6qkKR"},"source":["## random"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"nWUr-CGoqmkp","executionInfo":{"status":"ok","timestamp":1705075637519,"user_tz":-60,"elapsed":5,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["SEED = 42\n","os.environ['PYTHONHASHSEED']=str(SEED)\n","keras.utils.set_random_seed(SEED)\n","transformers.set_seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"uOVwghmrotM4"},"source":["## models"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeoklAmZoyfh","outputId":"49480ef3-b838-4e5a-c566-1ab0886f5c77","executionInfo":{"status":"ok","timestamp":1705075637519,"user_tz":-60,"elapsed":4,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['gpt2_base_en', 'gpt2_medium_en', 'gpt2_large_en', 'gpt2_extra_large_en', 'gpt2_base_en_cnn_dailymail']\n","['opt_125m_en', 'opt_1.3b_en', 'opt_2.7b_en', 'opt_6.7b_en']\n"]}],"source":["gpt2_types = list(keras_nlp.models.GPT2Backbone.presets.keys())\n","opt_types = list(keras_nlp.models.OPTBackbone.presets.keys())\n","print(gpt2_types)\n","print(opt_types)\n","GPT2 = gpt2_types[0]\n","OPT = opt_types[0]\n","PYTHIA = \"EleutherAI/pythia-160m-deduped\"\n","LLAMA = \"JackFram/llama-160m\""]},{"cell_type":"markdown","source":["## constraints"],"metadata":{"id":"5L8fJz6ExiYo"}},{"cell_type":"code","source":["DIR_CONSTRAINTS_PATH = '/content/drive/My Drive/Colab Notebooks/NLP_models_qa_testing/text-generation/constraints/'"],"metadata":{"id":"0w31SaHjxg2Y","executionInfo":{"status":"ok","timestamp":1705075637520,"user_tz":-60,"elapsed":5,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z2jBeTnco8ix"},"source":["# Datasets"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3R43FQM6aaL9","executionInfo":{"status":"ok","timestamp":1705075638020,"user_tz":-60,"elapsed":504,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["import datasets"]},{"cell_type":"markdown","metadata":{"id":"Kgtj3EWDG2RR"},"source":["## datasets"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"A-r52LWn9Jy3","executionInfo":{"status":"ok","timestamp":1705075638020,"user_tz":-60,"elapsed":4,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["SQUAD_V2 = \"squad_v2\"\n","SQL_CONTEXT = \"b-mc2/sql-create-context\"\n","ADVERSARIAL_QA = \"adversarial_qa\""]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zZncRXXwxWv","outputId":"585bed22-3377-4b81-c942-d0e8592f6016","executionInfo":{"status":"ok","timestamp":1705075640760,"user_tz":-60,"elapsed":2743,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["squad2 = datasets.load_dataset(SQUAD_V2)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"i8wSCAPP8-Rf","executionInfo":{"status":"ok","timestamp":1705075642126,"user_tz":-60,"elapsed":1369,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["sql = datasets.load_dataset(SQL_CONTEXT)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"FbSU3y578-3m","executionInfo":{"status":"ok","timestamp":1705075643956,"user_tz":-60,"elapsed":1833,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["adversarial_qa = datasets.load_dataset(ADVERSARIAL_QA, 'adversarialQA')"]},{"cell_type":"markdown","metadata":{"id":"sX9tgeJBh3mz"},"source":["## tokenizers"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"mzH7GntNiOIr","executionInfo":{"status":"ok","timestamp":1705075646196,"user_tz":-60,"elapsed":2242,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["gpt2_tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(GPT2)\n","opt_tokenizer = keras_nlp.models.OPTTokenizer.from_preset(OPT)\n","pythia_tokenizer = transformers.AutoTokenizer.from_pretrained(\n","  PYTHIA,\n","  revision=\"step103000\",\n","  cache_dir=\"./pythia-160m-deduped/step103000\",\n","  padding_side='left',\n","  model_max_length=1024,\n",")\n","llama_tokenizer = transformers.AutoTokenizer.from_pretrained(\n","    LLAMA,\n","    cache_dir=\"./llama/160m\",\n","    padding_side='left',\n","    model_max_length=1024,\n",")\n","\n","def lambda_pythia(input):\n","  tokens = pythia_tokenizer.batch_encode_plus(input, add_special_tokens=False, truncation=True)\n","  return tokens.input_ids\n","\n","def lambda_llama(input):\n","  tokens = llama_tokenizer.batch_encode_plus(input, add_special_tokens=False, truncation=True,)\n","  return tokens.input_ids\n","\n","\n","lambda_tokenizers = {\n","    GPT2: gpt2_tokenizer,\n","    LLAMA: lambda_llama,\n","    PYTHIA: lambda_pythia,\n","    OPT: opt_tokenizer,\n","}"]},{"cell_type":"markdown","metadata":{"id":"8aCBYRb_02pc"},"source":["## preprocess of data"]},{"cell_type":"code","source":["MAX_TOKENS = 128"],"metadata":{"id":"cWDRVdGHGSC2","executionInfo":{"status":"ok","timestamp":1705075646196,"user_tz":-60,"elapsed":3,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kDy2sBYTz0Vi","executionInfo":{"status":"ok","timestamp":1705075647563,"user_tz":-60,"elapsed":1370,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd"]},{"cell_type":"code","source":["def get_entire_dataset(dataset, names_arr):\n","  df_list = [dataset[name].to_pandas() for name in names_arr]\n","  return pd.concat(df_list)"],"metadata":{"id":"OSXaTyckCQ7l","executionInfo":{"status":"ok","timestamp":1705075647564,"user_tz":-60,"elapsed":5,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["squad2 = get_entire_dataset(squad2, ['train','validation'])\n","sql = get_entire_dataset(sql, ['train'])\n","adversarial_qa = get_entire_dataset(adversarial_qa, ['train','validation','test'])"],"metadata":{"id":"M9wsmEcoCR0V","executionInfo":{"status":"ok","timestamp":1705075648716,"user_tz":-60,"elapsed":1156,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def extract_answer(answer_dict):\n","    text_list = answer_dict.get('text', [])\n","    non_empty_text_list = [text for text in text_list if text]\n","    return non_empty_text_list[0] if non_empty_text_list else None"],"metadata":{"id":"1CxSZ4GaCVy8","executionInfo":{"status":"ok","timestamp":1705075648716,"user_tz":-60,"elapsed":3,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["ANSWER = 'answer'\n","CONTEXT = 'context'\n","QUESTION = 'question'\n","\n","SPLITS = ['train', 'validation', 'test']\n","\n","for dataset in [squad2, adversarial_qa]:\n","  dataset[ANSWER] = dataset['answers'].apply(extract_answer)\n","  dataset.dropna(subset=[ANSWER], inplace=True)"],"metadata":{"id":"dTPl0T0vCWOs","executionInfo":{"status":"ok","timestamp":1705075649574,"user_tz":-60,"elapsed":860,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kqaww3dhOKE","executionInfo":{"status":"ok","timestamp":1705075651214,"user_tz":-60,"elapsed":1643,"user":{"displayName":"Husar","userId":"14076509305213519843"}},"outputId":"ade1b028-38fe-416c-f931-068d71315dc2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"id":"I5bQWLo806IM","executionInfo":{"status":"ok","timestamp":1705075651215,"user_tz":-60,"elapsed":3,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["def create_constraints_qa(dataset, tokenizers, name):\n","  texts = []\n","  conditions = [True]*len(dataset)\n","  conditions = np.array(conditions)\n","\n","  for _, example in dataset.iterrows():\n","    context = example[CONTEXT]\n","    question = example[QUESTION]\n","    answer = example[ANSWER]\n","\n","    text = \"context:\" + context + \" question:\" + question + \" answer:\" + answer\n","    texts.append(text)\n","\n","  BATCH_SIZE = 256\n","  for tokenizer in iter(tokenizers):\n","    for i in range(0, len(texts), BATCH_SIZE):\n","      batch_texts = texts[i:i+BATCH_SIZE]\n","      tokenized_texts = tokenizer(batch_texts)\n","      batch_conditions = conditions[i:i+BATCH_SIZE]\n","      condition_tokenizer = np.array([len(tokens) < MAX_TOKENS-4 for tokens in tokenized_texts])\n","      np.logical_and(batch_conditions, condition_tokenizer, out=batch_conditions)\n","\n","  os.makedirs(DIR_CONSTRAINTS_PATH, exist_ok=True)\n","  np.save(f'{DIR_CONSTRAINTS_PATH}{name}.npy', conditions)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"6xBYabH0HOCM","executionInfo":{"status":"ok","timestamp":1705074616666,"user_tz":-60,"elapsed":1307590,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["squad2 = create_constraints_qa(squad2, lambda_tokenizers.values(), \"squad2\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"OlGxDMnW5Ulk","executionInfo":{"status":"ok","timestamp":1705075545382,"user_tz":-60,"elapsed":731534,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["sql = create_constraints_qa(sql, lambda_tokenizers.values(), \"sql\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"WbO6q7VQ6ODj","executionInfo":{"status":"ok","timestamp":1705076125516,"user_tz":-60,"elapsed":368810,"user":{"displayName":"Husar","userId":"14076509305213519843"}}},"outputs":[],"source":["adversarial_qa = create_constraints_qa(adversarial_qa, lambda_tokenizers.values(), \"adversarial_qa\")"]}]}